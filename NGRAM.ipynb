{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85635172",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# 1. Load dataset\n",
    "import pandas as pd\n",
    "df = pd.read_csv('AI_Human.csv')\n",
    "human_texts = df[df['label'] == 'human']['text']\n",
    "ai_texts = df[df['label'] == 'ai']['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e10ae9c7",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# 2. Split data\n",
    "from sklearn.model_selection import train_test_split\n",
    "train_human, val_human = train_test_split(human_texts, test_size=0.2, random_state=42)\n",
    "train_ai, val_ai = train_test_split(ai_texts, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc93d3a4",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# 3. Train model\n",
    "from Models.NgramModel import NgramModel\n",
    "model = NgramModel(n=3)\n",
    "model.train(train_human)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32a61572",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# 4. Score examples\n",
    "scores_human = [model.score(t) for t in val_human]\n",
    "scores_ai = [model.score(t) for t in val_ai]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "890284aa",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# 5. Find optimal threshold\n",
    "import numpy as np\n",
    "from sklearn.metrics import roc_curve, accuracy_score\n",
    "\n",
    "labels = [1]*len(scores_human) + [0]*len(scores_ai)\n",
    "scores = scores_human + scores_ai\n",
    "fpr, tpr, thresholds = roc_curve(labels, [-s for s in scores])  # negate because lower = more human\n",
    "best_threshold = thresholds[np.argmax(tpr - fpr)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4aa0318f",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# 6. Evaluate\n",
    "preds = [model.classify(t, best_threshold) for t in val_human] + \\\n",
    "        [model.classify(t, best_threshold) for t in val_ai]\n",
    "true = [\"human\"] * len(val_human) + [\"ai\"] * len(val_ai)\n",
    "print(\"Accuracy:\", accuracy_score(true, preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd02311e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_score, recall_score, f1_score, confusion_matrix, classification_report\n",
    "\n",
    "# Convert labels to binary format: \"human\" = 1, \"ai\" = 0\n",
    "y_true = [1] * len(val_human) + [0] * len(val_ai)\n",
    "y_pred = [1 if label == \"human\" else 0 for label in preds]\n",
    "\n",
    "print(\"Precision:\", precision_score(y_true, y_pred))\n",
    "print(\"Recall:\", recall_score(y_true, y_pred))\n",
    "print(\"F1 Score:\", f1_score(y_true, y_pred))\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_true, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b899c458",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine with text data\n",
    "val_texts = list(val_human) + list(val_ai)\n",
    "\n",
    "false_positives = [text for i, text in enumerate(val_texts) if y_true[i] == 0 and y_pred[i] == 1]\n",
    "false_negatives = [text for i, text in enumerate(val_texts) if y_true[i] == 1 and y_pred[i] == 0]\n",
    "\n",
    "print(f\"False Positives (AI as Human): {len(false_positives)}\")\n",
    "print(f\"False Negatives (Human as AI): {len(false_negatives)}\")\n",
    "\n",
    "# Show a few misclassified examples\n",
    "print(\"\\nExample False Positive:\")\n",
    "print(false_positives[0][:500])  # Show first 500 chars\n",
    "print(\"\\nExample False Negative:\")\n",
    "print(false_negatives[0][:500])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9687c376",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.hist(scores_human, bins=30, alpha=0.5, label='Human', color='blue')\n",
    "plt.hist(scores_ai, bins=30, alpha=0.5, label='AI', color='red')\n",
    "plt.axvline(best_threshold, color='black', linestyle='--', label='Threshold')\n",
    "plt.title(\"N-gram Model Score Distribution\")\n",
    "plt.xlabel(\"Average Negative Log Probability\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "227583d0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
